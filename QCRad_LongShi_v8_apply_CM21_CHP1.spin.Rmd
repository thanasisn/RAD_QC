---
title:       "QCRad methodology application."
author:      "Natsis Athanasios"
institute:   "AUTH"
affiliation: "Laboratory of Atmospheric Physics"
abstract:    "Data quality for radiation measurements as described by
              CN Long and Y Shi, September 2006, DOE/SC-ARM/TR-074.
              - The QCRad Value Added Product Surface
              Radiation Measurement Quality Control Testing Including
              Climatology_Long2006.pdf"

documentclass: article
classoption:   a4paper,oneside
fontsize:      10pt
geometry:      "left=0.5in,right=0.5in,top=0.5in,bottom=0.5in"

link-citations:  yes
colorlinks:      yes

header-includes:
- \usepackage{caption}
- \usepackage{placeins}
- \captionsetup{font=small}

output:
  bookdown::pdf_document2:
    number_sections:  no
    fig_caption:      no
    keep_tex:         no
    latex_engine:     xelatex
    toc:              yes
    fig_width:        8
    fig_height:       5
  html_document:
    toc: true
    fig_width:  9
    fig_height: 4
  pdf_document:
date: "`r format(Sys.time(), '%F')`"
---

**Source code: [github.com/thanasisn/RAD_QC](https://github.com/thanasisn/RAD_QC)**

### Notes ###

Run for each year and apply Quality control on radiation data based on ID.

The chosen levels and filters have to be evaluated with the available data.

reads: QCRad_LongShi_v8_id

exports:


```{r echo=F, include=T}


####_  Document options _####
knitr::opts_chunk$set(comment    = ""       )
# knitr::opts_chunk$set(dev        = "pdf"   )
knitr::opts_chunk$set(dev        = "png"    )
knitr::opts_chunk$set(out.height = "30%"   )
knitr::opts_chunk$set(fig.align  = "center" )
knitr::opts_chunk$set(cache      =  TRUE    )
# knitr::opts_chunk$set(fig.pos    = '!h'    )


####_  Set environment  _####
Sys.setenv(TZ = "UTC")
tic <- Sys.time()
Script.Name <- "./QCRad_LongShi_v8_apply_CM21_CHP1.R"
if (!interactive()) {
    pdf(    file = paste0("~/RAD_QC/RUNTIME/", basename(sub("\\.R$",".pdf", Script.Name))))
    sink(   file = paste0("~/RAD_QC/RUNTIME/", basename(sub("\\.R$",".out", Script.Name))), split = TRUE)
    filelock::lock(paste0("~/RAD_QC/RUNTIME/", basename(sub("\\.R$",".loc", Script.Name))), timeout = 0)
}

library(scales)
library(data.table)
source("~/CODE/FUNCTIONS/R/trig_deg.R")
source("~/RAD_QC/Functions_write_data.R")


####  Variables init  ####
DATA_BASE     <- "~/DATA/Broad_Band/QCRad_LongShi/"
IN_PREFIX     <- "LAP_QCRad_LongShi_v8_id_CM21_CHP1_"

DO_PLOTS      <- TRUE
if (interactive()) {
    DO_PLOTS      <- FALSE
}


####  Load all data  ####
fileslist <- list.files( path    = DATA_BASE,
                         pattern = paste0(IN_PREFIX, ".*.Rds"),
                         full.names = TRUE)
fileslist <- sort(fileslist)
DATA <- data.table()
for (afl in fileslist) {
    tmp  <- readRDS(afl)
    DATA <- rbind(DATA, tmp, fill = TRUE)
    rm(tmp)
}


## . . Limits definitions  ####
QS <- list(
    sun_elev_min     =  -2 * 0.103, # 0. Drop all data when sun is below this point
    sun_elev_no_neg  =   0,         # 0. Don't allow negative values below this sun angle
    glo_SWdn_min     =  -4,         # 1. MIN Physically Possible Limits
    dir_SWdn_min     =  -4,         # 1. MIN Physically Possible Limits
    glo_SWdn_min_ext =  -2,         # 2. MIN Extremely Rare Minimum Limits
    dir_SWdn_min_ext =  -2,         # 2. MIN Extremely Rare Minimum Limits
    dif_rati_min     =   0.001,     # 3. (12) extra comparison to check data
    dif_rati_max     =   1.01,      # 3. (13) extra comparison to check data 1
    clim_lim_C3      =   0.81,      # 4. Direct Climatological (configurable) Limit first level
    clim_lim_D3      =   0.90,      # 4. Direct Climatological (configurable) Limit second level
    clim_lim_C1      =   1.22,      # 4. Global Climatological (configurable) Limit first level
    clim_lim_D1      =   1.35,      # 4. Global Climatological (configurable) Limit second level
    ClrSW_a          = 1050.5,      # 5. Tracker off test Clear Sky factor a
    ClrSW_b          =   1.095,     # 5. Tracker off test Clear Sky factor b
    ClrSW_lim        =   0.85,      # 5. Tracker off test Threshold
    dir_glo_invert   =   3,         # 8. Test for inverted values: DIRhor - GLBhor > lim[%]
    dir_glo_glo_off  =   5,         # 8. Test for inverted values apply for GLBhor > offset
    CL_idx_max       =   1.3,       # 9. Clearness index test
    CL_idx_min       =  -0.001,     # 9. Clearness index test
    NULL
)


range(DATA$Date)




####  1. PHYSICALLY POSSIBLE LIMITS PER BSRN  ####
keys  <- c("Physical possible limit min (5)", "Physical possible limit max (6)")
```


\newpage
## 1. PHYSICALLY POSSIBLE LIMITS PER BSRN

Drop all data with flag: `r paste(keys)`.


```{r echo=F, include=T}

## find
sel_d <- DATA$QCF_DIR_01 %in% keys
sel_g <- DATA$QCF_GLB_01 %in% keys
## remove
DATA$wattDIR[sel_d] <- NA
DATA$wattGLB[sel_g] <- NA
DATA$QCF_DIR_01     <- NULL
DATA$QCF_GLB_01     <- NULL
## info
cat(c(sum(sel_d, na.rm = T), " Direct Records removed with:", keys), ".\n\n")
cat(c(sum(sel_g, na.rm = T), " Global Records removed with:", keys), ".\n\n")
if (sum(sel_d, sel_g) > 0) {
    ## more code to add
    cat("\n\n**CHECK OMITED DATA**\n\n")
}
```

-----------------------------------------------------------------------------

```{r echo=F, include=T}




####  4. Climatological (configurable) Limits  ####
keys  <- c("Second climatological limit (16)",
           "First climatological limit (17)")
```


\newpage
## 4. Climatological (configurable) Limits

Drop all data with flag: `r paste(keys)`.


```{r echo=F, include=T}

# levels(DATA$QCF_GLB_04.1)
# levels(DATA$QCF_GLB_04.2)
# levels(DATA$QCF_DIR_04.1)
# levels(DATA$QCF_DIR_04.2)

if (DO_PLOTS) {
    ## test direct
    temp1 <- DATA[ !is.na(QCF_DIR_04.1) ]
    temp2 <- DATA[ !is.na(QCF_DIR_04.2) ]
    for (ad in unique(c(as.Date(temp2$Date),as.Date(temp1$Date)))) {
        pp <- DATA[ as.Date(Date) == ad, ]
        if (any(!is.na(pp$wattDIR))) {
            second <- pp[,TSIextEARTH_comb * QS$clim_lim_D3 * cosde(SZA)^0.2 + 15 ]
            first  <- pp[,TSIextEARTH_comb * QS$clim_lim_C3 * cosde(SZA)^0.2 + 10 ]
            ylim <- range(second,first,pp$wattDIR, na.rm = T)
            plot(pp$Date, pp$wattDIR, "l",
                 ylim = ylim, ylab = "", xlab = "wattDIR")
            lines(pp$Date, second, col = "pink" )
            lines(pp$Date, first,  col = "red" )
            title(as.Date(ad, origin = "1970-01-01"))
            # points(pp[!is.na(QCF_DIR_04.1)|!is.na(QCF_DIR_04.2) , Date],
            #        pp[!is.na(QCF_DIR_04.1)|!is.na(QCF_DIR_04.2) , wattDIR],
            #        ylim = ylim, col = "blue")
            points(pp[wattDIR > second | wattDIR > first , Date],
                   pp[wattDIR > second | wattDIR > first , wattGLB],
                   ylim = ylim, col = "red", pch = 1)
        }
    }

    ## test global
    temp1 <- DATA[ !is.na(QCF_GLB_04.1) ]
    temp2 <- DATA[ !is.na(QCF_GLB_04.2) ]
    for (ad in unique(c(as.Date(temp2$Date),as.Date(temp1$Date)))) {
        pp <- DATA[ as.Date(Date) == ad, ]
        if (any(!is.na(pp$wattGLB))) {
            second <- pp[,TSIextEARTH_comb * QS$clim_lim_D1 * cosde(SZA)^1.2 + 60 ]
            first  <- pp[,TSIextEARTH_comb * QS$clim_lim_C1 * cosde(SZA)^1.2 + 60 ]
            ylim <- range(second,first,pp$wattDIR, na.rm = T)
            plot(pp$Date, pp$wattGLB, "l",
                 ylim = ylim, xlab = "", ylab = "wattGLB")
            lines(pp$Date, second, col = "pink" )
            lines(pp$Date, first,  col = "red" )
            title(as.Date(ad, origin = "1970-01-01"))
            # points(pp[!is.na(QCF_GLB_04.1)|!is.na(QCF_GLB_04.2) , Date],
            #        pp[!is.na(QCF_GLB_04.1)|!is.na(QCF_GLB_04.2) , wattGLB],
            #        ylim = ylim, col = "blue")
            points(pp[wattGLB > first, Date],
                   pp[wattGLB > first, wattGLB],
                   ylim = ylim, col = "red", pch = 1)
            points(pp[wattGLB > second, Date],
                   pp[wattGLB > second, wattGLB],
                   ylim = ylim, col = "blue", pch = 1)
        }
    }
}

## find
sel_d <- DATA$QCF_DIR_04.1 %in% keys | DATA$QCF_DIR_04.2 %in% keys
sel_g <- DATA$QCF_GLB_04.1 %in% keys | DATA$QCF_GLB_04.2 %in% keys
## remove
DATA$wattDIR[sel_d] <- NA
DATA$wattGLB[sel_g] <- NA
DATA$QCF_DIR_04.1   <- NULL
DATA$QCF_DIR_04.2   <- NULL
DATA$QCF_GLB_04.1   <- NULL
DATA$QCF_GLB_04.2   <- NULL
## remove empty entries
DATA <- DATA[!(is.na(wattDIR) & is.na(wattGLB)), ]
## info
cat(c(sum(sel_d, na.rm = T),
      " Direct Records removed with:",
      keys), ".\n\n")
cat(c(sum(sel_g, na.rm = T),
      " Global Records removed with:",
      keys), ".\n\n")
```

-----------------------------------------------------------------------------

```{r echo=F, include=T}




####  8. Test for inverted values  ####
keys <- c("Direct > global hard (15)","Direct > global soft (14)")
```


\newpage
## 8. Test for inverted values

Drop all data with flag: `r paste(keys)`.

When the Direct on horizontal level is greater than a %
from the Global.

This denotes obstacles on the morning mostly, or very low
signals when Sun is near the horizon. And possible
cases of Instrument windows cleaning.


```{r echo=F, include=T}

if (DO_PLOTS) {
    ## use the applied limits
    lim1 <- QS$dir_glo_invert
    off1 <- QS$dir_glo_glo_off

    hist(DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & Elevat  > 3,    Elevat])
    hist(DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & Elevat  > 3,    wattHOR - wattGLB])
    hist(DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, Elevat])
    hist(DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, wattHOR - wattGLB])

    # test <- DATA[ !is.na(QCF_BTH_08), ]
    # test <- DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1 & Elevat > 15 ]
    test <- DATA[ 100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1  ]

    for (ad in unique(as.Date(test$Date))) {
        pp   <- DATA[ as.Date(Date) == ad, ]
        ylim <- range(pp$wattGLB, pp$wattHOR, na.rm = T)
        plot( pp$Date, pp$wattHOR, "l",
              ylim = ylim, col = "blue", ylab = "", xlab = "")
        lines(pp$Date, pp$wattGLB, col = "green" )
        title(as.Date(ad, origin = "1970-01-01"))
        points(pp[100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, Date],
               pp[100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, wattHOR],
               ylim = ylim, col = "blue")
        points(pp[100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, Date],
               pp[100*(wattHOR - wattGLB)/wattGLB > lim1 & wattGLB > off1, wattGLB],
               ylim = ylim, col = "green")
    }

}

## remove
DATA[ QCF_BTH_08 %in% keys, wattGLB := NA ]
DATA[ QCF_BTH_08 %in% keys, wattHOR := NA ]
DATA[ QCF_BTH_08 %in% keys, wattDIR := NA ]
## info
cat(c(DATA[ QCF_BTH_08 %in% keys, .N ], " Global or Direct Records removed with:", keys), ".\n\n")
## remove empty entries
DATA <- DATA[!(is.na(wattDIR) & is.na(wattGLB)), ]
DATA$QCF_BTH_08 <- NULL
```

-----------------------------------------------------------------------------

```{r echo=F, include=T}




####  9. Clearness index test  ####
keys  <- c("Clearness index limit max (19)",
           "Clearness index limit min (20)")
```


\newpage
## 9. Clearness index test

Drop all data with flag: `r paste(keys)`.

These data are near Elevation 0 and caused by the cos(SZA)
kt = GLB / (cos(sza) * TSI)
low GLB value end extreme cos(sza) values


```{r echo=F, include=T}

if (DO_PLOTS) {
    # levels(DATA$QCF_GLB_09)
    hist(DATA[ QCF_GLB_09 %in% keys,              wattGLB], breaks = 100 )
    hist(DATA[ QCF_GLB_09 %in% keys,              Elevat ], breaks = 100 )
    hist(DATA[ QCF_GLB_09 %in% keys & Elevat > 2, wattGLB], breaks = 100 )
    hist(DATA[ QCF_GLB_09 %in% keys & Elevat > 2, Elevat ], breaks = 100 )

    # test <- DATA[ , .(Min_kt =  min(Clearness_Kt, na.rm = T),
    #                   Max_kt =  max(Clearness_Kt, na.rm = T)),
    #               by = .(Elevat = (Elevat %/% 0.01) * 0.01 ) ]
    # plot(test$Elevat, test$Max_kt)
    # plot(test$Elevat, test$Min_kt)

    # DATA[ Clearness_Kt >  10 , Clearness_Kt := NA]
    # DATA[ Clearness_Kt < -20 , Clearness_Kt := NA]
    # min(DATA$SZA)
    # max(DATA$SZA)
    # cosde(90.00000001)
    # cosde(89.99999999)

    tmp <- DATA[ Elevat < 120 ]
    for (ay in unique(year(tmp$Date))) {
        pp <- tmp[year(tmp$Date) == ay]
        # plot(pp$Azimuth, pp$wattGLB, main = ay, pch = 19, cex = 0.1)
        # points(pp[QCF_GLB_09 %in% keys,Azimuth],
        #      pp[QCF_GLB_09 %in% keys,wattGLB],
        #      pch = 19, cex = 0.2, col = "red")
        ylim = c(-20, 20)
        # plot(pp$Azimuth, pp$Clearness_Kt, main = ay, pch = 19, cex = 0.1, ylim = ylim)
        # points(pp[QCF_GLB_09 %in% keys,Azimuth],
        #        pp[QCF_GLB_09 %in% keys,Clearness_Kt],
        #        pch = 19, cex = 0.2, col = "red")
        #
        # abline(h = QS$CL_idx_max, col = "cyan", lwd = 0.5)
        # abline(h = QS$CL_idx_min, col = "cyan", lwd = 0.5)
        ylim = c(-0.5, 2)
        plot(pp$Elevat, pp$Clearness_Kt,
             main = ay, pch = 19, cex = 0.1,
             ylim = ylim, xlab = "Elevation", ylab = "Clearness index Kt" )
        points(pp[Clearness_Kt > QS$CL_idx_max, Elevat],
               pp[Clearness_Kt > QS$CL_idx_max, Clearness_Kt],
               pch = 19, cex = 0.3, col = "red")
        points(pp[Clearness_Kt < QS$CL_idx_min, Elevat],
               pp[Clearness_Kt < QS$CL_idx_min, Clearness_Kt],
               pch = 19, cex = 0.3, col = "blue")
        abline(h = QS$CL_idx_max, col = "cyan", lwd = 0.5)
        abline(h = QS$CL_idx_min, col = "cyan", lwd = 0.5)
    }
}

## remove
DATA[QCF_GLB_09 %in% keys, wattGLB := NA]
## info
cat(c(DATA[QCF_GLB_09 %in% keys, .N],
      " Global Records removed with:",
      keys), ".\n\n")
## remove empty entries
DATA <- DATA[!(is.na(wattDIR) & is.na(wattGLB)), ]
DATA$QCF_GLB_09 <- NULL
```

-----------------------------------------------------------------------------

```{r echo=F, include=T}










#### ~ 6. Rayleigh Limit Diffuse Comparison ~ ####
keys  <- c("Rayleigh diffuse limit (18)")

Rayleigh_diff <- function(SZA, Pressure) {

    source("~/CODE/FUNCTIONS/R/trig_deg.R")

    a    <-   209.3
    b    <-  -708.3
    c    <-  1128.7
    d    <-  -911.2
    e    <-   287.85
    f    <-     0.046725
    mu_0 <- cosde(SZA)

    return( a * mu_0     +
                b * mu_0 ^ 2 +
                c * mu_0 ^ 3 +
                d * mu_0 ^ 4 +
                e * mu_0 ^ 5 +
                f * mu_0 * Pressure )
}
```


\newpage
## 6. Rayleigh Limit Diffuse Comparison

Compare inferred diffuse radiation with a modeled value of diffuse,
based on SZA and atmospheric pressure.

Reasons:
- Difference on Sun observation angle due to different instruments location.
- Cases of instrument windows cleaning


```{r }
# #' `r print(Rayleigh_diff)`
```



```{r echo=F, include=T}



DATA[ , RaylDIFF := Rayleigh_diff(SZA = SZA, Pressure = pressure) ]


test <- unique(DATA[ wattGLB > 50 &
                    (wattDIF / wattGLB) < 0.8 &
                     wattDIF < (RaylDIFF - 1),  ])

hist(test$Azimuth, breaks = 100)
hist(test$SZA, breaks = 100)

test <- unique(DATA[ wattGLB > 50 &
                     (wattDIF / wattGLB) < 0.8 &
                     wattDIF < (RaylDIFF - 1)  &
                         SZA < 70,  ])


for (ad in unique(as.Date(test$Date))) {
    pp   <- DATA[ as.Date(Date) == ad, ]

    layout(matrix(c(1,2), 2, 1, byrow = TRUE))
    par(mar = c(2,4,2,1))

    ylim <- range(pp$wattDIF, pp$RaylDIFF, na.rm = T)
    plot( pp$Date, pp$wattDIF, "l",
          ylim = ylim, col = "cyan", ylab = "Diffuse", xlab = "")
    lines(pp$Date, pp$RaylDIFF, col = "red" )
    title(as.Date(ad, origin = "1970-01-01"))
    # par(new = T)

    par(mar = c(2,4,1,1))
    ylim <- range(pp$wattGLB, pp$wattDIR, na.rm = T)
    plot( pp$Date, pp$wattGLB, "l",
          ylim = ylim, col = "green", ylab = "", xlab = "")
    lines(pp$Date, pp$wattDIR, col = "blue" )

    points(pp[wattGLB > 50 & (wattDIF / wattGLB) < 0.8 & wattDIF < (RaylDIFF - 1), Date],
           pp[wattGLB > 50 & (wattDIF / wattGLB) < 0.8 & wattDIF < (RaylDIFF - 1), wattDIR],
           ylim = ylim, col = "red")
    points(pp[wattGLB > 50 & (wattDIF / wattGLB) < 0.8 & wattDIF < (RaylDIFF - 1), Date],
           pp[wattGLB > 50 & (wattDIF / wattGLB) < 0.8 & wattDIF < (RaylDIFF - 1), wattGLB],
           ylim = ylim, col = "red")
    cat("\n")

}
```
```{r echo=F, include=T}






#### ~ Rest of the flags to check ~ ####

wecare <- grep("QCF_DIR_|QCF_GLB_|QCF_BTH_" , names(DATA), value = T )
for (fg in wecare) {
    if (all(is.na(DATA[[fg]]))) {
        DATA[[fg]] <- NULL
    }
}


wecare <- grep("QCF_DIR_|QCF_GLB_|QCF_BTH_" , names(DATA), value = T )

for (fg in wecare) {
    cat(paste(fg),"\n")
    cat(levels(DATA[[fg]]),"\n")
}
```



```{r }
# for (fg in wecare) {
#     if (any(!is.na(DATA[[fg]]))) {
#         try(hist( as.numeric( factor(DATA[[fg]]), main = fg)))
#         try(plot(DATA$Date, factor(DATA[[fg]]), main = fg))
#     }
# }
#
#
# #+ echo=F, include=T, results="asis"
# ## loop years and read data
# for (YY in yearSTA:yearEND) {
#
#     cat("\n\n\\FloatBarrier\n\n")
#     cat("\\newpage\n\n")
#     cat("\n## Year:", YY, "\n\n")
#
#


#     #### ~ ~ ~ ~  Data export ~ ~ ~ ~ ##########################################
#     cat(paste("\nExport Data.\n\n"))
#
#     ## . . gather all suspect points for export ----------------------------####
#     # suspect_choose  <- DATA_year$QCF_DIR != "good" | DATA_year$QCF_GLB != "good"
#     # SUS_DATA        <- DATA_year[suspect_choose,]
#     # SUS_DATA        <- SUS_DATA[order(SUS_DATA$Date30),]
#     # SUS_DATA_gather <- rbind(SUS_DATA_gather, SUS_DATA)
#
#     # ## gather all suspect dates for export
#     # daysinfo        <- SUS_DATA[,c("Date30","QCF_DIR","QCF_GLB")]
#     # daysinfo$Day    <- as.Date(daysinfo$Date30)
#     # daysinfo$Date30 <- NULL
#     # daysinfo        <- daysinfo[order(daysinfo$Day),]
#     # daysinfo        <- unique(daysinfo)
#     # daysinfo_gather <- rbind(daysinfo_gather, daysinfo)


# #    ## save data identification
# #    DATA_year <- DATA_year[ DATA_year$Date < LAST_DAY_EXPR , ]
# #    DATA_year <- DATA_year[ DATA_year$Date > PROJECT_START , ]
#
#    ## . . Export main data -------------------------------------------------####
#    if ( !TESTING & dim(DATA_year)[1] > 0 ) {
#        write_RDS(object = DATA_year,
#                  file   = paste0(OUTPUT_BASE, basename(sub("\\.R$","_", Script.Name)),YY))
#    }
#     ##-------------------------------------------------------------------------##
#
#
# #    ##-- Strict output for clear sky use ---------------------------------------
# #    allow <- c( "good", "Possible Direct Obstruction (23)")
# #    sels  <- DATA_year$QCF_DIR %in% allow | DATA_year$QCF_GLB %in% allow
# #    STRICT_data <- DATA_year[sels,]
# #
# #    STRICT_data <- subset(STRICT_data, select = c( -CHP1temp,
# #                                                   -CHP1tempSD,
# #                                                   -CHP1tempUNC,
# #                                                   -chp1TempCF,
# #                                                   -TSIextEARTH_comb
# #                                                   ))
# #
# #    ##-- Export strict data --------------------------------------------------##
# #    if ( !TESTING & dim(STRICT_data)[1] > 0 ) {
# #        myRtools::write_RDS(object = STRICT_data, paste0(OUTPUT_STRICT,YY)) }
# #    ##------------------------------------------------------------------------##
#
# }
#
# # ##-- Export a record of the bad data -----------------------------------------##
# # if (!TESTING) myRtools::write_RDS( SUS_DATA_gather, SUSPECTS_EXP )
# # ##----------------------------------------------------------------------------##
#
```


**END**

```{r include=T, echo=F}
tac <- Sys.time()
cat(sprintf("%s %s@%s %s %f mins\n\n",Sys.time(),Sys.info()["login"],Sys.info()["nodename"],Script.Name,difftime(tac,tic,units="mins")))
```

